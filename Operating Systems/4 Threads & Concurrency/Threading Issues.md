# Threading Issues

## Semantics of `fork()` ans `exec()`

If one thread in a program calls `fork()`, does the new process duplicate all threads, or is the new process single-threaded?

- **fork** - Some UNIXes have two version of fork
	- duplicate all threads
	- duplicate only one thread
- **exec** - replace the current process image with a new program (used after fork)
	- If a thread invokes the `exec()` system call, the program specified in the parameter to `exec()` will replace the entire process—including all threads

## Signal Handling

A *signal* is used in UNIX systems to notify a process that a particular event has occurred

- A *signal handler* is used to process signals
	1. Signal is generated by particular event
	2. Signal is delivered to a process
	3. Signal is handled by one of two signal handlers
		- default
		- user-defined
- Every signal has *default handler* that kernel runs when handling signal
	- *User-defined signal handler* can override default
	- For single-threaded, signal delivered to process
	- For multi-threaded
		- Deliver to the thread which the signal applies
			- In case error happens in a thread
		- Deliver to every thread in the process
			- Good for sharing global data
		- Deliver to certain threads in the process
			- Consider that your app have different types of worker threads
		- Assign a specific thread to receive all signals for the process
			- Can help centralize the signal handling logic, making it easier to manage and debug signal-related issues
			 - Logging

## Thread Cancellation

Thread cancellation involves terminating a thread before it has completed. For example, if multiple threads are concurrently searching through a database and one thread returns the result, the remaining threads might be canceled.

A thread that is to be canceled is often referred to as the *target thread*.

- Cancellation of a target thread may occur in two different scenarios
	- **Asynchronous cancellation**. One thread immediately terminates the target thread.
		- one thread to monitor
		- Examples
			- web servers when request is taking too long
			- GUI apps interrupting background thread
	- **Deferred cancellation** (default). The target thread periodically checks whether it should terminate, allowing it an opportunity to terminate itself in an orderly fashion.
		- the thread monitor itself
		- Examples
			- parallel data processing when error is encountered in one of the processing task
			- distributed systems when checking for connection's health or responsiveness

Invoking `pthread_cancel()` indicates only a request to cancel the target thread, however; actual cancellation depends on how the target thread is set up to handle the request

Pthreads supports three cancellation modes. Each mode is defined as a state and a type, as illustrated in the table below. A thread may set its cancellation state and type using an API.

|Mode|State|Type|
|-|-|-|
|Off|Disabled|–|
|Deferred|Enabled |Deferred|
|Asynchronous|Enabled|Asynchronous|

- If thread has cancellation disabled, cancellation remains pending until thread enables it
- On Linux systems, thread cancellation is handled through signals

## Thread-Local Storage (TLS)

Thread-local storage (TLS) is a mechanism used in multithreaded programming to provide each thread in a process with *its own unique storage for variables*. It allows variables to have *thread-specific values*, meaning that each thread can access and modify its own private copy of a variable without interfering with other threads' copies of the same variable.

It is easy to confuse TLS with local variables. However, local variables are visible only during a single function invocation, whereas TLS data are visible across function invocations.

- TLS allows each thread to have its own copy of data
- Useful when you do not have control over the thread creation process (i.e., when using a [[Implicit Threading#Thread Pools|thread pools]])
- Different from local variables
	- Local variables visible only during single function invocation
	- TLS visible across function invocations
- Similar to `static` data (TLS is unique to each thread)

> In C++, the `thread_local` keyword is used to define thread-local variables at the global or namespace scope or as static class members. It *cannot be used with local variables* within a function.

C++ Example using `thread_local`:

```c++
#include <iostream>
#include <thread>

thread_local int threadSpecificValue = 0;

void incrementThreadLocalValue() {
    // Each thread has its own copy of threadSpecificValue
    threadSpecificValue++;
    std::cout << "Thread ID: " << std::this_thread::get_id() << ", Thread-local value: " << threadSpecificValue << std::endl;
}

int main() {
    std::thread t1(incrementThreadLocalValue);
    std::thread t2(incrementThreadLocalValue);
    std::thread t3(incrementThreadLocalValue);

    t1.join();
    t2.join();
    t3.join();

    return 0;
}
```

Output:

```bash
Thread ID: 12345, Thread-local value: 1
Thread ID: 67890, Thread-local value: 1
Thread ID: 13579, Thread-local value: 1
```

## Scheduler Activations

In multithreaded programs, communication between the kernel and the thread library is crucial for efficient management of threads. The [[#Many-to-Many|many-to-many]] and [[#Two-level|two-level]] thread models often use an intermediate data structure called [[Lightweight Processes (LWPs)]] to connect user-level threads with kernel threads.

![[Pasted image 20230731151550.png|Lightweight process]]

- Typically use an intermediate data structure between user and kernel threads–lightweight process (LWP)
	- Appears to be a virtual processor on which process can schedule user thread to run
	- Each LWP attached to kernel thread
 - Scheduler activations provide *upcalls* - a communication mechanism from the kernel to the *upcall handler* in the thread library
 - This communication allows an application to maintain the correct number of kernel threads

The overall flow of scheduler activations is as follows:

- When a user-level thread blocks (e.g., waiting for I/O), the corresponding LWP is notified by the kernel through an upcall. The upcall handler executes on the LWP to handle the blocking event, which may include scheduling another eligible user-level thread on the LWP or allocating a new LWP to handle other tasks.
- When the event causing the blocking to occur completes, the kernel notifies the user-level thread library through another upcall. The upcall handler, again running on the corresponding LWP, takes appropriate action, such as marking the previously blocked thread as eligible for execution.

### Upcalls

Upcalls are a central mechanism of scheduler activations. They allow the kernel to inform the user-level thread library about specific events that require attention. These events include thread blocking (e.g., due to I/O or synchronization operations) and unblocking (e.g., when a blocking operation completes). When such events occur, the kernel makes an upcall to the user-level thread library.

### Upcall handler

The user-level thread library provides upcall handlers, which are functions that are executed in response to upcalls from the kernel. Upcall handlers run on the corresponding LWP and allow the user-level thread library to take appropriate actions based on the event.
